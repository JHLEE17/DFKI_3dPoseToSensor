{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tcn import TCN, tcn_full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = \"1\"\n",
    "random.seed(SEED)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV files\n",
    "input_df = pd.read_csv(\"./subject1_walking_15_17_11_2_MFthr5.csv\")\n",
    "gt_df = pd.read_csv(\"./acc_walking_forearm_18455_s1.csv\")\n",
    "input_np = np.array(input_df)\n",
    "gt_np = np.array(gt_df)\n",
    "\n",
    "# get spine length to normalize\n",
    "neck = input_np[:,6:9]\n",
    "center = input_np[:,9:]\n",
    "spine_len = np.sqrt(np.sum((neck-center)**2, axis=1))\n",
    "plt.plot(spine_len)\n",
    "\n",
    "# second derivate\n",
    "input_np_norm_by_spine = input_np[:,:6]/(np.array([spine_len]*6).T )\n",
    "input_np_derivate = np.gradient(input_np_norm_by_spine, axis=0)\n",
    "input_np_derivate_2 = np.gradient(input_np_derivate, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data):\n",
    "    # Calculate the mean along the first axis (each column)\n",
    "    mean = np.mean(data, axis=0)\n",
    "    # Calculate the standard deviation along the first axis (each column)\n",
    "    std_dev = np.std(data, axis=0)\n",
    "    # Standardize the data\n",
    "    standardized_data = (data - mean) / std_dev\n",
    "    return standardized_data\n",
    "\n",
    "# input_np_std = standardize_data(input_np)\n",
    "input_np_std = standardize_data(input_np_derivate_2)\n",
    "gt_np_std = standardize_data(gt_np)\n",
    "\n",
    "\n",
    "window_size = 60\n",
    "\n",
    "input_data_windows = np.array([input_np_std[i-window_size:i,:] for i in range(window_size, input_np_std.shape[0])])\n",
    "target_data_windows = gt_np_std[window_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define TCN model\n",
    "inputs = tf.keras.Input(shape=(window_size, 6))    \n",
    "\n",
    "x = TCN(nb_filters=64,\n",
    "                kernel_size=10,\n",
    "                nb_stacks=2,\n",
    "                dilations=(1, 2, 4, 8, 16, 32, 64),\n",
    "                padding='same',\n",
    "                use_skip_connections=True,\n",
    "                dropout_rate=0.3,\n",
    "                return_sequences=False,                 \n",
    "                kernel_initializer='he_normal',\n",
    "                use_batch_norm=False,\n",
    "                use_layer_norm=False,\n",
    "                use_weight_norm=False,\n",
    "                activation=\"tanh\")(inputs)        \n",
    "outputs = tf.keras.layers.Dense(3, dtype=tf.float32)(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "callbacks = [\n",
    "                DisplayCallback(),\n",
    "                tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=0, patience=5),\n",
    "                tf.keras.callbacks.ModelCheckpoint(\"./output/V8.h5\", monitor=\"mse\", mode=\"min\", save_best_only=False)\n",
    "            ]\n",
    "\n",
    "def scale_fn(x):\n",
    "    return 1/(2.**(x-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper-parameters\n",
    "lr = tfa.optimizers.CyclicalLearningRate(1e-4, 1e-2, step_size=20, scale_fn=scale_fn, scale_mode=\"cycle\")\n",
    "optimizer = tfa.optimizers.Lookahead(tfa.optimizers.AdaBelief(learning_rate=lr))\n",
    "optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(input_data_windows, target_data_windows, epochs=1000, validation_split=0.2, callbacks=callbacks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validation: last 20% of training data  (Original)\n",
    "# val_input = input_data_windows[int(input_df.shape[0]*0.8):]\n",
    "# val_target = target_data_windows[int(input_df.shape[0]*0.8):]\n",
    "\n",
    "# print(val_input.shape)\n",
    "# print(val_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "val_input_df = pd.read_csv(\"./subject1_running_15_17_MFthr5.csv\")\n",
    "val_gt_df = pd.read_csv(\"./acc_running_forearm_7200_s1.csv\")\n",
    "\n",
    "val_input_np = np.array(val_input_df)\n",
    "val_gt_np = np.array(val_gt_df)\n",
    "\n",
    "# mean and std from training dataset\n",
    "# val_input_np_std = (val_input_np-input_mean)/input_std\n",
    "# val_gt_np_std = (val_gt_np- gt_mean)/gt_std\n",
    "\n",
    "# mean and std from validation dataset\n",
    "val_input_np_std = standardize_data(val_input_np)\n",
    "val_gt_np_std = standardize_data(val_gt_np)\n",
    "\n",
    "\n",
    "val_input_data_windows = np.array([val_input_np_std[i-window_size:i,:] for i in range(window_size, val_input_np_std.shape[0])])\n",
    "val_target_data_windows = val_gt_np_std[window_size:]\n",
    "\n",
    "val_input = val_input_data_windows[:int(val_input_df.shape[0]*0.5)]\n",
    "val_target = val_target_data_windows[:int(val_input_df.shape[0]*0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the actual vs predicted values for a specific target column\n",
    "# target_column = 0  # Change this to the column you want to visualize\n",
    "start=0\n",
    "end=len(val_target)\n",
    "# end=60\n",
    "for target_column in range(3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(val_target[start:end, target_column], label='Actual')\n",
    "    plt.plot(val_predictions[start:end, target_column], label='Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
